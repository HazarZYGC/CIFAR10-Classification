{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization,Concatenate\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = []\n",
    "label_test = []\n",
    "def reading_train(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes') \n",
    "    train = dict[b'data']\n",
    "    train = train.reshape((len(train), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    for i in dict[b'labels']:\n",
    "        label_train.append(i)\n",
    "    return train\n",
    "\n",
    "def reading_test(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes') \n",
    "    train = dict[b'data']\n",
    "    train = train.reshape((len(train), 3, 32, 32)).transpose(0, 2, 3, 1)   \n",
    "    for i in dict[b'labels']:\n",
    "        label_test.append(i)\n",
    "    return train\n",
    "\n",
    "df1 = reading_train('data_batch_1')\n",
    "df2 = reading_train('data_batch_2')\n",
    "df3 = reading_train('data_batch_3')\n",
    "df4 = reading_train('data_batch_4')\n",
    "df5 = reading_train('data_batch_5')\n",
    "ataboi = np.concatenate((df1,df2,df3,df4,df5))\n",
    "dftest = reading_test('test_batch') \n",
    "ataboi.shape\n",
    "len(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented = []\n",
    "i = 0\n",
    "for item in ataboi:\n",
    "    flip_1 = np.fliplr(item)\n",
    "    flip_2 = np.flipud(item)\n",
    "    augmented.append(flip_1)\n",
    "    augmented.append(flip_2)\n",
    "    label_train.append(label_train[i])\n",
    "    label_train.append(label_train[i])\n",
    "    i = i+1\n",
    "len(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x139850bd348>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(augmented[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ataboi = np.concatenate((ataboi,arr))\n",
    "len(ataboi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ataboi,dftest = ataboi / 255.0, dftest / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135000 samples, validate on 15000 samples\n",
      "Epoch 1/50\n",
      "135000/135000 [==============================] - 100s 742us/step - loss: 1.4527 - accuracy: 0.4832 - val_loss: 1.0242 - val_accuracy: 0.6304\n",
      "Epoch 2/50\n",
      "135000/135000 [==============================] - 96s 708us/step - loss: 0.9862 - accuracy: 0.6501 - val_loss: 0.8507 - val_accuracy: 0.6923\n",
      "Epoch 3/50\n",
      "135000/135000 [==============================] - 94s 699us/step - loss: 0.8362 - accuracy: 0.7073 - val_loss: 0.7868 - val_accuracy: 0.7254\n",
      "Epoch 4/50\n",
      "135000/135000 [==============================] - 96s 709us/step - loss: 0.7419 - accuracy: 0.7410 - val_loss: 0.6362 - val_accuracy: 0.7717\n",
      "Epoch 5/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.6778 - accuracy: 0.7648 - val_loss: 0.5985 - val_accuracy: 0.7905\n",
      "Epoch 6/50\n",
      "135000/135000 [==============================] - 96s 708us/step - loss: 0.6318 - accuracy: 0.7811 - val_loss: 0.5838 - val_accuracy: 0.7933\n",
      "Epoch 7/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.5983 - accuracy: 0.7945 - val_loss: 0.5817 - val_accuracy: 0.7974\n",
      "Epoch 8/50\n",
      "135000/135000 [==============================] - 97s 717us/step - loss: 0.5724 - accuracy: 0.8016 - val_loss: 0.5484 - val_accuracy: 0.8068\n",
      "Epoch 9/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.5458 - accuracy: 0.8120 - val_loss: 0.5637 - val_accuracy: 0.8062\n",
      "Epoch 10/50\n",
      "135000/135000 [==============================] - 98s 724us/step - loss: 0.5254 - accuracy: 0.8186 - val_loss: 0.5244 - val_accuracy: 0.8168\n",
      "Epoch 11/50\n",
      "135000/135000 [==============================] - 98s 724us/step - loss: 0.5069 - accuracy: 0.8257 - val_loss: 0.5158 - val_accuracy: 0.8189\n",
      "Epoch 12/50\n",
      "135000/135000 [==============================] - 99s 734us/step - loss: 0.4935 - accuracy: 0.8293 - val_loss: 0.4884 - val_accuracy: 0.8319\n",
      "Epoch 13/50\n",
      "135000/135000 [==============================] - 97s 722us/step - loss: 0.4800 - accuracy: 0.8346 - val_loss: 0.4633 - val_accuracy: 0.8389\n",
      "Epoch 14/50\n",
      "135000/135000 [==============================] - 100s 741us/step - loss: 0.4673 - accuracy: 0.8390 - val_loss: 0.4502 - val_accuracy: 0.8447\n",
      "Epoch 15/50\n",
      "135000/135000 [==============================] - 96s 710us/step - loss: 0.4552 - accuracy: 0.8435 - val_loss: 0.4546 - val_accuracy: 0.8423\n",
      "Epoch 16/50\n",
      "135000/135000 [==============================] - 96s 713us/step - loss: 0.4453 - accuracy: 0.8462 - val_loss: 0.4481 - val_accuracy: 0.8433\n",
      "Epoch 17/50\n",
      "135000/135000 [==============================] - 94s 697us/step - loss: 0.4363 - accuracy: 0.8493 - val_loss: 0.4679 - val_accuracy: 0.8393\n",
      "Epoch 18/50\n",
      "135000/135000 [==============================] - 93s 688us/step - loss: 0.4273 - accuracy: 0.8525 - val_loss: 0.4778 - val_accuracy: 0.8349\n",
      "Epoch 19/50\n",
      "135000/135000 [==============================] - 92s 685us/step - loss: 0.4199 - accuracy: 0.8539 - val_loss: 0.4507 - val_accuracy: 0.8445\n",
      "Epoch 20/50\n",
      "135000/135000 [==============================] - 94s 694us/step - loss: 0.4125 - accuracy: 0.8569 - val_loss: 0.4728 - val_accuracy: 0.8422\n",
      "Epoch 21/50\n",
      "135000/135000 [==============================] - 95s 705us/step - loss: 0.4036 - accuracy: 0.8599 - val_loss: 0.4436 - val_accuracy: 0.8482\n",
      "Epoch 22/50\n",
      "135000/135000 [==============================] - 94s 700us/step - loss: 0.3998 - accuracy: 0.8613 - val_loss: 0.4346 - val_accuracy: 0.8497\n",
      "Epoch 23/50\n",
      "135000/135000 [==============================] - 94s 699us/step - loss: 0.3922 - accuracy: 0.8643 - val_loss: 0.4205 - val_accuracy: 0.8552\n",
      "Epoch 24/50\n",
      "135000/135000 [==============================] - 94s 697us/step - loss: 0.3876 - accuracy: 0.8656 - val_loss: 0.4661 - val_accuracy: 0.8443\n",
      "Epoch 25/50\n",
      "135000/135000 [==============================] - 96s 708us/step - loss: 0.3825 - accuracy: 0.8666 - val_loss: 0.4262 - val_accuracy: 0.8552\n",
      "Epoch 26/50\n",
      "135000/135000 [==============================] - 95s 701us/step - loss: 0.3744 - accuracy: 0.8707 - val_loss: 0.4266 - val_accuracy: 0.8563\n",
      "Epoch 27/50\n",
      "135000/135000 [==============================] - 94s 699us/step - loss: 0.3732 - accuracy: 0.8705 - val_loss: 0.4357 - val_accuracy: 0.8535\n",
      "Epoch 28/50\n",
      "135000/135000 [==============================] - 95s 705us/step - loss: 0.3673 - accuracy: 0.8724 - val_loss: 0.4165 - val_accuracy: 0.8599\n",
      "Epoch 29/50\n",
      "135000/135000 [==============================] - 95s 700us/step - loss: 0.3618 - accuracy: 0.8751 - val_loss: 0.4234 - val_accuracy: 0.8591\n",
      "Epoch 30/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.3580 - accuracy: 0.8754 - val_loss: 0.4017 - val_accuracy: 0.8643\n",
      "Epoch 31/50\n",
      "135000/135000 [==============================] - 96s 709us/step - loss: 0.3570 - accuracy: 0.8761 - val_loss: 0.4065 - val_accuracy: 0.8614\n",
      "Epoch 32/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.3521 - accuracy: 0.8773 - val_loss: 0.4225 - val_accuracy: 0.8579\n",
      "Epoch 33/50\n",
      "135000/135000 [==============================] - 94s 700us/step - loss: 0.3476 - accuracy: 0.8793 - val_loss: 0.4337 - val_accuracy: 0.8525\n",
      "Epoch 34/50\n",
      "135000/135000 [==============================] - 94s 700us/step - loss: 0.3456 - accuracy: 0.8795 - val_loss: 0.4100 - val_accuracy: 0.8593\n",
      "Epoch 35/50\n",
      "135000/135000 [==============================] - 95s 700us/step - loss: 0.3439 - accuracy: 0.8812 - val_loss: 0.4063 - val_accuracy: 0.8643\n",
      "Epoch 36/50\n",
      "135000/135000 [==============================] - 95s 701us/step - loss: 0.3369 - accuracy: 0.8822 - val_loss: 0.4152 - val_accuracy: 0.8610\n",
      "Epoch 37/50\n",
      "135000/135000 [==============================] - 94s 700us/step - loss: 0.3332 - accuracy: 0.8835 - val_loss: 0.4029 - val_accuracy: 0.8635\n",
      "Epoch 38/50\n",
      "135000/135000 [==============================] - 94s 700us/step - loss: 0.3315 - accuracy: 0.8844 - val_loss: 0.4170 - val_accuracy: 0.8591\n",
      "Epoch 39/50\n",
      "135000/135000 [==============================] - 94s 696us/step - loss: 0.3275 - accuracy: 0.8863 - val_loss: 0.4203 - val_accuracy: 0.8596\n",
      "Epoch 40/50\n",
      "135000/135000 [==============================] - 94s 695us/step - loss: 0.3235 - accuracy: 0.8881 - val_loss: 0.3889 - val_accuracy: 0.8691\n",
      "Epoch 41/50\n",
      "135000/135000 [==============================] - 95s 704us/step - loss: 0.3206 - accuracy: 0.8882 - val_loss: 0.3932 - val_accuracy: 0.8705\n",
      "Epoch 42/50\n",
      "135000/135000 [==============================] - 94s 699us/step - loss: 0.3190 - accuracy: 0.8892 - val_loss: 0.4015 - val_accuracy: 0.8669\n",
      "Epoch 43/50\n",
      "135000/135000 [==============================] - 95s 700us/step - loss: 0.3178 - accuracy: 0.8887 - val_loss: 0.4053 - val_accuracy: 0.8625\n",
      "Epoch 44/50\n",
      "135000/135000 [==============================] - 95s 701us/step - loss: 0.3126 - accuracy: 0.8908 - val_loss: 0.3808 - val_accuracy: 0.8725\n",
      "Epoch 45/50\n",
      "135000/135000 [==============================] - 97s 715us/step - loss: 0.3122 - accuracy: 0.8910 - val_loss: 0.3962 - val_accuracy: 0.8696\n",
      "Epoch 46/50\n",
      "135000/135000 [==============================] - 95s 705us/step - loss: 0.3097 - accuracy: 0.8923 - val_loss: 0.3912 - val_accuracy: 0.8711\n",
      "Epoch 47/50\n",
      "135000/135000 [==============================] - 97s 717us/step - loss: 0.3078 - accuracy: 0.8928 - val_loss: 0.3915 - val_accuracy: 0.8687\n",
      "Epoch 48/50\n",
      "135000/135000 [==============================] - 97s 722us/step - loss: 0.3057 - accuracy: 0.8935 - val_loss: 0.3868 - val_accuracy: 0.8708\n",
      "Epoch 49/50\n",
      "135000/135000 [==============================] - 96s 714us/step - loss: 0.3051 - accuracy: 0.8929 - val_loss: 0.3777 - val_accuracy: 0.8733\n",
      "Epoch 50/50\n",
      "135000/135000 [==============================] - 97s 722us/step - loss: 0.2996 - accuracy: 0.8953 - val_loss: 0.3787 - val_accuracy: 0.8721\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ataboi,label_train,epochs=50,batch_size=64,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 372us/step\n",
      "Test loss: 0.3606984977245331\n",
      "Test accuracy: 0.8820000290870667\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(dftest, label_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
